# Sistemas de recomendación y filtrado colaborativo

En esta sección discutiremos métodos que se pueden utilizar
para hacer recomendaciones de documentos, películas, artículos, etc.
a personas según sus intereses.

- **Problema**: predecir la respuesta de personas a estímulos a los que no han sido expuestos,
basados en respuesta a otros estímulos de esta y quizá otras personas similares.

Por ejemplo, si consideramos usuarios de Netflix: ¿qué tanto le puede gustar a X la película Y? Usuarios de Amazon: ¿qué tan probable es que compren Z artículo si se les ofrece?


## Enfoques de recomendación

Hay varios enfoques que podemos utilizar para atacar este problema:

- **Principalmente basados en contenido**:  En función de características de los estímulos, productos o películas (por ejemplo, género, actores, país de origen, año, etc.) intentamos predecir el gusto por el estímulo. En este enfoque, construimos variables derivadas del contenido de los artículos (por ejemplo: qué actores salen, año, etc. o en textos palabras que aparecen), e intentamos predecir el gusto a partir de esas características. 

Ejemplo: Si mu gustó *Twilight* entonces el sistema recomienda otros dramas+vampiros ("por ejemplo entrevista con un vampiro", por contenido).

- **Principalmente colaborativos**: utilizamos gustos o intereses de usuarios/artículos similares --- en el sentido de que les han gustado los mismos artículos/les gustaron a las mismas personas.

Ejemplo: Me gustó StarWars y Harry Potter, varios otros usuarios a los que también les gustaron estas dos películas también les gustó "Señor de los anillos", así que recomendamos "Señor de los Anillos". Entre estos métodos, veremos principalmente métodos basados en reducción de dimensionalidad o  **modelos de factores latentes**: encontrar factores latentes que describan usuarios y películas, y predecimos dependiendo de los niveles de factores latentes de personas y películas.


## Datos

Los datos utilizados para este tipo de sistemas son de dos
tipos:


- Ratings  *explícitos* dados por los usuarios (por ejemplo, Netflix mucho tiempo fue así: $1-5$ estrellas). Esto es cada vez más raro porque tienes que forzar al individuo a calificar y eso puede no ser muy transparente. 

- Ratings *implícitos* que se derivan de la actividad de los usuarios (por ejemplo, vio la película completa, dio click en la descripción de un producto, etc.). 



### Ejemplo {-}

Consideramos evaluaciones en escala de gusto: por ejemplo $1-5$ estrellas, o $1$-me disgustó mucho, $5$-me gustó mucho, etc.

Podemos representar las evaluaciones como una matriz:

```{r, echo=FALSE}
mat.cons <- matrix('-', 4, 6)
mat.cons[1,1] <- '3';mat.cons[1,2] <- '5';mat.cons[1,3] <- '5';mat.cons[1,4] <- '2'
mat.cons[2,1] <- '3';mat.cons[2,3] <- '4';
mat.cons[3,4] <- '5'; mat.cons[3,5] <- '4'
mat.cons[4,1] <- '1';mat.cons[4,3] <- '2';mat.cons[4,5] <- '5';mat.cons[4,6] <- '4';
rownames(mat.cons) <- c('a','b','c','d')
colnames(mat.cons) <- c('SWars1','SWars4','SWars5','HPotter1','HPotter2','Twilight')
knitr::kable(data.frame(mat.cons))
mat.cons.o <- mat.cons
```

En las filas tenemos a los individuos y el las columnas las distintas películas que han calificado. 


Y lo que queremos hacer es predecir los valores faltantes de esta matriz y estimar el gusto del individuo por la película y seleccionar para cada usuario los artículos con predicción más alta. Por ejemplo

```{r, echo=FALSE}
mat.cons <- matrix(round(runif(24, 1,5),1), 4, 6)
mat.cons[1,1] <- '3';mat.cons[1,2] <- '5';mat.cons[1,3] <- '5';mat.cons[1,4] <- '2'
mat.cons[2,1] <- '3';mat.cons[2,3] <- '4';
mat.cons[3,4] <- '5'; mat.cons[3,5] <- '4'
mat.cons[4,1] <- '1';mat.cons[4,3] <- '2';mat.cons[4,5] <- '5';mat.cons[4,6] <- '4';
rownames(mat.cons) <- c('a','b','c','d')
colnames(mat.cons) <- c('SWars1','SWars4','SWars5','HPotter1','HPotter2','Twilight')
knitr::kable(data.frame(mat.cons))
```

Podemos pensar en este problema como uno de **imputación de datos faltantes**. Las dificultades 
particulares de este problema son:

- Datos ralos: cada usuario sólo ha visto y calificado una proporción baja de películas, y hay películas con pocas vistas.
- Escalabilidad: el número de películas y usuarios es generalmente grande

Por estas razones, típicamente no es posible usar técnicas estadísticas de imputación de datos (como imputación estocástica basada en regresión)

- Usaremos mejor métodos más simples basados en similitud entre usuarios y películas y descomposición de matrices.

## Modelos de referencia y evaluación

Vamos a comenzar considerando modelos muy simples. El primero que se nos puede ocurrir es uno
de homogeneidad de gustos: para una persona $i$, nuestra predicción de su gusto por la película
$j$ es simplemente la media de la película $j$ sobre todos los usuarios que la han visto. Este sería un buen modelo si los gustos fueran muy parecidos sobre todos los usuarios.

Introducimos la siguente notación:

- $x_{ij}$ es la evaluación del usuario $i$ de la película $j$. Obsérvese que muchos de estos valores no son observados (no tenemos información de varias $x_{ij}$). Por lo tanto $X$ es una matriz llena de NA's. 
- $\hat{x}_{ij}$ es la predicción que hacemos de gusto del usuario $i$ por la película $j$


En nuestro primer modelo simple, nuestra predicción es simplemente
$$\hat{x}_{ij} = \hat{b}_j$$
donde 
$$\hat{b_j} = \frac{1}{N_j}\sum_{s} x_{sj},$$
es el promedio de las calificaciones otrogadas por los $N_j$ usuarios que vieron (y calificaron) la película $j$.

¿Cómo evaluamos nuestras predicciones?

### Evaluación de predicciones

Usamos muestras de entrenamiento y validación. Como en el concurso de Netflix,
utilizaremos la raíz del error cuadrático medio:

$$RECM =\left ( \frac{1}{T} \sum_{(i,j) \, observada} (x_{ij}-\hat{x}_{ij})^2 \right)^{\frac{1}{2}}$$

aunque también podríamos utilizar la desviación absoluta media:

$$DAM =\frac{1}{T} \sum_{(i,j) \, observada} |x_{ij}-\hat{x}_{ij}|$$

- Nótese que estas dos cantidades se evaluán sólo sobre los pares $(i,j)$ para los
que tengamos una observación $x_{ij}$.

**Observaciones**:

- Generalmente evaluamos sobre un conjunto de validación separado del conjunto
de entrenamiento.

- Escogemos una muestra de películas, una muestra de usuarios, y ponemos
en validación el conjunto de calificaciones de esos usuarios para esas películas. 

- Para hacer un conjunto de prueba, idealmente los datos deben ser de películas
que hayan sido observadas por los usuarios en el futuro (después del periodo de los
datos de entrenamiento).

- Nótese que no seleccionamos *todas* las evaluaciones de un usuario, ni *todas* las
evaluaciones de una película. Con estas estrategias, veríamos qué pasa con nuestro
modelo cuando tenemos una película que no se ha visto o un usuario nuevo.
Lo que queremos ententer es cómo se desempeña nuestro sistema
cuando tenemos cierta información de usuarios y de películas.
![](../Img_Validacion_Netflix.png)

### Ejemplo: datos de Netflix {-}


Los datos del concurso de Netflix originalmente vienen en archivos de texto, un archivo por película.


The movie rating files contain over $100$ million ratings from $480$ thousand
randomly-chosen, anonymous Netflix customers over $17$ thousand movie titles.  The
data were collected between October, $1998$ and December, $2005$ and reflect the
distribution of all ratings received during this period.  The ratings are on a
scale from $1$ to $5$ (integral) stars. To protect customer privacy, each customer
id has been replaced with a randomly-assigned id.  The date of each rating and
the title and year of release for each movie id are also provided.

The file "training_set.tar" is a tar of a directory containing $17770$ files, one
per movie.  The first line of each file contains the movie id followed by a
colon.  Each subsequent line in the file corresponds to a rating from a customer
and its date in the following format:

CustomerID,Rating,Date

- MovieIDs range from $1$ to $17770$ sequentially.
- CustomerIDs range from $1$ to $2649429$, with gaps. There are $480189$ users.
- Ratings are on a five star (integral) scale from $1$ to $5$.
- Dates have the format YYYY-MM-DD.

---

En primer lugar haremos un análisis exploratorio de los datos para entender algunas
de sus características, luego ajustamos el modelo simple de gustos homogéneos (la predicción es el
promedio de calificaciones de cada película), y lo evaluamos.

Comenzamos por cargar los datos:

```{r, message = FALSE}
# Cargar librerías
library(tidyverse)
library(sparklyr)

# Template para gráficas
theme_set(theme_minimal())

# Paleta de colores
cb_palette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
```


```{r leertabla1, message=FALSE}
# Leer los datos de películas
pelis_nombres <- read_csv('../datos/netflix/movies_title_fix.csv', col_names = FALSE, na = c("", "NA", "NULL"))

# Asigna nombres de variables 
names(pelis_nombres) <- c('peli_id','año','nombre')

# Vemos los datos 
head(pelis_nombres)

# Leer calificaciones de usuarios
dat_netflix <- read_csv( "../datos/netflix/dat_muestra_nflix.csv", progress = FALSE) %>% 
    select(-usuario_id_orig) %>% 
    mutate(usuario_id = as.integer(as.factor(usuario_id)))

# Vemos los datos
head(dat_netflix)

# No de observaciones
dat_netflix %>% tally
```


Y ahora calculamos las medias de cada película: 

```{r}
# Calcular calificación promedio 
medias_pelis <- dat_netflix %>% # datos
  group_by(peli_id) %>% # agrupar por película
    summarise(media_peli = mean(calif), num_calif_peli = n()) # calcular la media de calificaciones y el no de calificaciones

# Agrega la media al a base de películas 
medias_pelis <- left_join(medias_pelis, pelis_nombres)
```

```{r}

# Películas mejor calificadas
arrange(medias_pelis, desc(media_peli)) %>% # Ordena peliculas por media descendiente
  top_n(200, media_peli) %>% # Muestra las 200 peliculas mejor calificadas
  mutate(media_peli = round(media_peli, 2)) %>% # redondea la calificacion
  DT::datatable()
```

Nótese que varias de las películas con mejor promedio tienen muy pocas evaluaciones. Podemos
examinar más detalladamente graficando número de evaluaciones vs promedio:


```{r}
# Grafica de calif promedio vs no de calificaciones
ggplot(medias_pelis, aes(x=num_calif_peli, y=media_peli)) + 
  geom_point(alpha = 0.1) + xlab("Número de calificaciones") + 
  ylab("Promedio de calificaciones") 
```


Y vemos que hay más variabilidad en los promedios cuando hay menos evaluaciones, como
es de esperarse. Esta forma de embudo ("raíz de n") se puede explicar por el tamaño de muestra que estamos usando.


¿Puedes ver algún problema que tendremos que enfrentar con el modelo simple? Hay muchas películas con muy pocas calificaciones; además, aún para las películas con un gran no. de calificaciones, hay demasiada varaiblidad en las mismas. 


Si filtramos por número de calificaciones (al menos $500$ por ejemplo), 
estas son las películas mejor calificadas (la mayoría conocidas y populares):

```{r}
# Filtrar películas con al menos 500 calificaciones
arrange(medias_pelis, desc(media_peli)) %>% # ordena por calif promedio
  filter(num_calif_peli > 500) %>% # elimina obs con menos de 500 calif
  top_n(200, media_peli) %>%  # 200 pelis mejor calificadas
  mutate(media_peli = round(media_peli, 2)) %>% # redondea calificación
  DT::datatable()
```

Ahora seleccionamos nuestra muestra de entrenamiento y de validación. Seleccionamos una
muestra de usuarios y de películas:

```{r}
# Fija la semilla 
set.seed(28882)

# Extrae los distnitos usuarios existentes 
usuarios <- dat_netflix %>% select(usuario_id) %>% distinct

# Muestreo del 20% de usuarios para validación 
valida_usuarios <- usuarios %>% sample_frac(0.2) 

# Extrae las distintas películas 
peliculas <-  dat_netflix %>% select(peli_id) %>% distinct

# Muestreo del 20% de peliuclas para validación 
valida_pelis <- peliculas %>% sample_frac(0.2)
```

Y separamos calificaciones de entrenamiento y validación:

```{r}
# Extrae conjunto de validación. 
# Nota: el semi-join es una union de tipo filtro. Elige los datos que están en A para los que hay un match en B. 
dat_valida <- dat_netflix %>% semi_join(valida_usuarios) %>% semi_join(valida_pelis) 

# Extrea el conjunto de entrenamiento 
# Nota: el anti-join es una unión de tipo filtro. Devuelve los renglones de A que no están en B. 
dat_entrena <- dat_netflix %>% anti_join(dat_valida)

# No observaciones en valiación y en entrenaiento 
n_valida <- dat_valida %>% tally %>% pull(n)
n_entrena <- dat_entrena %>% tally %>% pull(n)

# Imprime resumen de la separación de muestras. 
sprintf("Entrenamiento: %1d, Validación: %2d, Total: %3d", n_entrena, 
        n_valida, n_entrena + n_valida)
```

Ahora construimos predicciones con el modelo simple de arriba y evaluamos con validación:

```{r, message = FALSE}
# Calcula la callificación promedio por película para el set de entrenamiento
medias_pred <- dat_entrena %>% # datos entrenamiento
  group_by(peli_id) %>% # agrupa por película
  summarise(media_pred = mean(calif)) # calificación promedio. 

# Calcula la calificación media para todas las películas
media_total_e <- dat_entrena %>% # datos de entrenamiento
  ungroup %>% # desagrupa
  summarise(media = mean(calif)) %>% # calcula la media de todas las observaciones
  pull(media) # extrae la media. 

# Agrega la predicción de la calificacion a las pelis y usuarios
# en la muestra de validación
dat_valida_pred <- dat_valida %>% # datos validación
  left_join(medias_pred %>% collect()) # agrega las medias de la predicción 

# Ver los datos 
head(dat_valida_pred)
```

Nota que puede ser que algunas películas seleccionadas en validación no tengan evaluaciones en entrenamiento:
```{r}
# busca las peliculas en validación que no tienen predicción de media 
# En este caso no hay ninguna
table(is.na(dat_valida_pred$media_pred))

# Si alguna fuera na, se reemplaza con la media total estimada, en caso contrario, 
# con la predicción estimada. 
dat_valida_pred <- mutate(dat_valida_pred,
        media_pred = ifelse(is.na(media_pred), media_total_e, media_pred))
```

No sucede en este ejemplo, pero si sucediera podríamos usar el promedio general de las predicciones que calculamos como predicción para dicha película. Evaluamos ahora el error:

```{r}

# Función para calcular la raíz del error cuadrático medio. 
recm <- function(calif, pred){
  sqrt(mean((calif - pred)^2))
}

# Obtiene el erro en el set de validación 
error <- dat_valida_pred %>% # datos validacion
  ungroup %>% # desagrupa
  summarise(error = mean((calif - media_pred)^2)) # calcula el ECM y promedia para el set

# Error
error
```

Este error está en las mismas unidades de las calificaciones (estrellas en este caso).

---

Antes de seguir con nuestra refinación del modelo, veremos algunas
observaciones acerca del uso de escala en análisis de datos:

Cuando tratamos con datos en escala encontramos un problema técnico que es el uso distinto
de la escala por los usuarios, muchas veces **independientemente de sus gustos**

Veamos los datos de Netflix para una muestra de usuarios:


```{r}
# muestra de 50 usuarios de entrenamiento
entrena_usu <- sample(unique(dat_entrena$usuario_id), 50)

# Extrae los datos para los usuarios muestreados 
muestra_graf <- filter(dat_entrena, usuario_id %in% entrena_usu)

# medias generales por usuario, ee de la media
muestra_res <- muestra_graf %>% # datos 
  group_by(usuario_id) %>% # agrupa por usuario
  summarise(media_calif = mean(calif), 
            sd_calif = sd(calif)/sqrt(length(calif))) # obtiene la calificación promedio y la ds por usuario 

# Re ordena la muestra por calificación promedio
muestra_res$usuario_id <- reorder(factor(muestra_res$usuario_id), muestra_res$media_calif)

# Grafica la media ya la desviación estándar de cda usuario. 
ggplot(muestra_res, aes(x=factor(usuario_id), y = media_calif, 
        ymin = media_calif - sd_calif, ymax = media_calif + sd_calif)) + 

  geom_linerange() + geom_point() + xlab('Usuario') + ylab('Calificación promedio')+
  theme(axis.text.x=element_blank())
```

Y notamos que hay heterogeneidad en el uso de las calificaciones: unos usuarios tienen promedios por encima de 4.5, mienstras que otros califican por debajo de 3 en promedio.  Aunque esto puede deberse a las películas que han visto,
generalmente una componente de esta variabilidad se debe a cómo usa la escala cada usuario. En este sentido un 4 o un 3 no significa nada porque para algunos 4 es muy bueno pero para otros es muy malo.


Y notamos que hay unos usuarios que tienen promedios por encima de $4.5$, mienstras que otros
califican por debajo de $3$ en promedio. Aunque esto puede deberse a las películas que han visto,
generalmente una componente de esta variabilidad se debe a cómo usa la escala cada usuario.
>>>>>>> 7c7b2b9d4b084fbf3c618dde3b9665d52eafb7d3

En primer lugar, quizá uno podría pensar que un modelo base consiste de simplemente
predecir el promedio de una película sobre todos los usuarios que la calificaron (sin incluir el sesgo de cada persona). Esto no funciona bien porque típicamente hay distintos patrones
de uso de la escala de calificación, que depende más de forma de uso de escala que de la calidad de los items.

Hay personas que son:

- Barcos: $5$,$5$,$5$,$4$,$4$,$5$ 
- Estrictos: $2$,$3$,$3$,$1$,$1$,$2$
- No se compromete: $3$,$3$,$3$,$3$,$4$
- Discrimina: $5$,$4$,$5$,$1$,$2$,$4$

El estilo de uso de las escalas varía por persona.
Puede estar asociado a aspectos culturales (países
diferentes usan escalas de manera diferente), quizá también de personalidad,
y a la forma de obtener las evaluaciones (cara a cara, por teléfono, internet).

Lo primero que vamos a hacer para controlar esta fuente de variación es ajustar las predicciones
dependiendo del promedio de calificaciones de cada usuario.


### (Opcional) Efectos en análisis de heterogeneidad en uso de escala.

 Muchas veces se considera que tratar como numéricos a calificaciones en escala no es muy apropiado, y que el análisis no tiene por qué funcionar pues en realidad las calificaciones están en una escala ordinal. Sin embargo,

- La razón principal por las que análisis de datos en escala es difícil *no es que usemos valores numéricos para los puntos de la escala*. Si esto fuera cierto, entonces por ejemplo, transformar una variable con logaritmo también sería "malo".

- La razón de la dificultad es que generalmente tenemos que lidiar con la  **heterogeneidad** en uso de la escala antes de poder obtener resultados útiles de nuestro análisis.


Supongamos que $X_1$ y $X_2$ son evaluaciones de dos películas. Por la discusión de arriba, podríamos escribir

$$X_1 = N +S_1,$$
$$X_2 = N + S_2,$$

donde $S_1$ y $S_2$ representan el gusto por las películas 1 y 2 respectivamente, y $N$ representa el nivel general
de calificaciones. Aquí $N$ es como el sesgo de cortesía. Lo que nos gustaría calcular es la correlación entre $S_1$ y $S_2$. 

Consideramos que $X_1$ y $X_2$ son variables aleatorias pues $N$ varía con las personas, igual que $S_1$ y $S_2$.

Podemos calcular

$$Cov(X_1,X_2)$$

para estimar el grado de correlación de *gusto por las dos películas*, como si fueran variables numéricas. Esta no es muy buena idea, pero no tanto porque se 
trate de variables ordinales, sino porque en realidad quisiéramos calcular:

$$Cov(S_1, S_2)$$

que realmente representa la asociación entre el gusto por las dos películas. El problema
es que $S_1$ y $S_2$ son variables que no observamos.

¿Cómo se relacionan estas dos covarianzas?

$$Cov(X_1,X_2)=Cov(N+S_1, N+S_2)=Cov(N,N) + Cov(S_1,S_2) + Cov(N, S_2)+Cov(N,S_1)$$

Tenemos que $Cov(N,N)=Var(N)=\sigma_N ^2$, y suponiendo que el gusto
no está correlacionado con los niveles generales 
de respuesta, $Cov(N_1, S_2)=0=Cov(N_2,S_1)$, de modo que

$$Cov(X_1,X_2)= Cov(S_1,S_2) + \sigma_N^2.$$


donde $\sigma_N^2$ no tiene qué ver nada con el gusto por las películas. Esto es, las correlaciones se inflan por la variabiliad en el sesgo de cortesía y no per-sé porque exista la cortesía. 


De forma que el usar estimaciones de $Cov(X_1,X_2)$ para estimar $Cov(S_1,S_2)$ puede
ser mala idea porque el sesgo hacia arriba puede ser alto, especialmente si la gente varía mucho
es un sus niveles generales de calificaciones (hay muy barcos y muy estrictos).

### Ejemplo {#ejemplo}

Los niveles generales de $50$ personas:

```{r}
# Fija la semilla 
set.seed(128)

# Tamaño muestra 
n <- 50

# Fija nivel primedio por persona 
niveles <- data_frame(persona = 1:n, nivel = rnorm(n,2))
```

Ahora generamos (simulamos) los gustos (latentes) por dos artículos, que suponemos
con correlación negativa:

```{r} 
# Simula calificaciones 
x <- rnorm(n)

# Simula gustos. 
gustos <- data.frame(persona=1:n, gusto_1 = x + rnorm(n),
                     gusto_2 = -x + rnorm(n))

# Exanuba la tabla de gustos 
head(gustos,3)

# Calcula la corrleación de los gustos
cor(gustos[,2:3])
```

Estos dos items tienen gusto correlacionado negativamente:
```{r, fig.width=5, fig.asp = 0.7}
# Grafica de gustos por los items 1 y 2
ggplot(gustos, aes(x=gusto_1, y=gusto_2)) + geom_point() +
    geom_smooth()
```   


Pero las mediciones no están correlacionadas:
```{r}
# Simula las medicions del gusto ie X_j=N+sj
medicion_1 <- niveles$nivel + gustos$gusto_1+rnorm(n,0.3)
medicion_2 <- niveles$nivel + gustos$gusto_2+rnorm(n,0.3)

# Data frame de mediciones 
mediciones <- data_frame(persona = 1:n, medicion_1, medicion_2)

# Correlaciones
cor(mediciones[,2:3])
```



Así que aún cuando el gusto por $1$ y $2$  están correlacionadas negativamente, las 
**mediciones** de gusto no están correlacionadas.

```{r, fig.width=5, fig.asp = 0.7}

# Graficas de las mediciones del gusto items 1 y 2
ggplot(mediciones, aes(x=medicion_1, y=medicion_2)) +
    geom_point() + geom_smooth()
```

En este ejemplo, el sesgo de corrtesía mueve las dos variables en el mismo sentido por lo tanto, pueden tener una correlación alta aunque no estén verdaderamente correlacionadas. 


**Observaciones**: Un modelado más cuidadoso de este tipo de datos requiere más trabajo. Pero para
el trabajo usual, generalmente intentamos controlar parte de la heterogeneidad
**centrando** las calificaciones por usuario. Es decir, a cada calificación
de una persona le restamos la media de sus calificaciones, que es una estimación
del nivel general $N$. Esta idea funciona si **$k$ no es muy chico**.


Si el número de calificaciones por persona ($k$) es chico,
entonces tenemos los siguientes problemas:

- El promedio de evaluaciones es una estimación ruidosa del nivel general.

- Podemos terminar con el problema opuesto: nótese que
si $X_1,\ldots, X_k$ son mediciones de gusto distintos items, y $\bar{X}$ es la estimación del nivel $N$, entonces $S_j=X_j-\bar{X}$ y se tiene que 

$$Cov(X_1-\bar{X}, X_2-\bar{X})=Cov(S_1-\bar{S},S_2-\bar{S}),$$
$$=Cov(S_1,S_2)-Cov(S_1,\bar{S})-Cov(S_2,\bar{S}) + Var(\bar{S})$$

Si $k$ es chica, suponiendo que los gustos no están correlacionados,
los términos intermedios puede tener valor negativo relativamente grande
$\left( \text{es de orden} \frac{1}{k}\left)$, 
aún cuando el último término sea chico (de orden $\tfrac{1}{k^2}$)

Así que ahora las correlaciones estimadas pueden tener sesgo hacia 
abajo, especialmente si $k$ es chica.

Más avanzado, enfoque bayesiano: <https://www.jstor.org/stable/2670337>

## Modelo de referencia 

Ahora podemos plantear el modelo base de referencia. Este modelo es útil para hacer
benchmarking de intentos de predicción, como primera pieza para construcción de modelos
más complejos, y también como una manera simple de producir estimaciones cuando no hay datos suficientes para hacer otro tipo de predicción.


```{block2, type='resumen'}
Si $x_{ij}$ es el gusto del usuario $i$ por la película $j$, entonces nuestra predicción
es
$$\hat{x}_{ij} = \hat{b}_j +  (\hat{a}_i-\hat{\mu} ) $$

donde $a_i$ indica un nivel general de calificaciones del usuario $i$, y $b_j$ es el nivel general de gusto por la película. 
```

Entonces, ajusto la media general de la película $j$ ($\hat{b}_j$) con la desviación de las calificaciones promedio del usuario $i$ ($\hat{a}_i$) respecto al promedio de general de las calificaciones $\hat{\mu}$.


Usualmente ponemos:

1. Media general
$$\hat{\mu} =\frac{1}{T}\sum_{s,t} x_{st}$$
2. Promedio de calificaciones de usuario $i$ 
$$\hat{a}_i =\frac{1}{M_i}\sum_{t} x_{i,t} $$
3. Promedio de calificaciones de la película $j$ 
$$\hat{b}_j =\frac{1}{N_j}\sum_{s} x_{s,j}$$

También podemos escribir, en términos de desviaciones:

$$\hat{x}_{ij} = \hat{\mu}  +  \hat{c}_i +  \hat{d}_j $$
donde:

1. Media general
$$\hat{\mu} =\frac{1}{T}\sum_{s,t} x_{st}$$
2. Desviación de las calificaciones de usuario $i$ respecto a la media general
$$\hat{c}_i =\frac{1}{M_i}\sum_{t} x_{it} - \hat{\mu} $$
3. Desviación  de la película $j$ respecto a la media general
$$\hat{d}_j =\frac{1}{N_j}\sum_{s} x_{sj}- \hat{\mu}$$


Una vez que observamos una calificación $x_{ij}$, el residual del modelo de referencia es
$$r_{ij} = x_{ij} - \hat{x}_{ij}$$

### Ejercicio: modelo de referencia para netflix {-}

Calculamos media de películas, usuarios y total:

```{r}
# Calcula la media de calificacions por usuario (a_i)
medias_usuarios <- dat_entrena %>% # datos de entrenamiento
    group_by(usuario_id) %>% # agrupa por usuario
    summarise(media_usu = mean(calif), num_calif_usu = length(calif)) %>% # media calif y no de calif. 
    select(usuario_id, media_usu, num_calif_usu) # selecciona variables 

# Calcula la media de las películas (b_j)
medias_peliculas <- dat_entrena %>% # datos de entrenamiento
    group_by(peli_id) %>% # agrupa por película 
    summarise(media_peli = mean(calif), num_calif_peli = length(calif)) %>% # media calif y no. de calif.
    select(peli_id, media_peli, num_calif_peli) # selecciona variables. 

# Calcula la media total (mu)
media_total_e <- mean(dat_entrena$calif)
```

Y construimos las predicciones para el conjunto de validación

```{r}
# Predicciones para el conjunto de validación 
dat_valida <- dat_valida %>% # datos de validación
  left_join(medias_usuarios) %>% # Agrega media de usuarios
  left_join(medias_peliculas) %>% # Agrega media de peliculas
  mutate(media_total = media_total_e) %>% # Agrga media total 
  mutate(pred = media_peli + (media_usu - media_total)) %>% # Predicción de calif. 
  mutate(pred = ifelse(is.na(pred), media_total, pred)) # los NA se cambian por la media total. 
```


Nótese que cuando no tenemos predicción bajo este modelo para una combinación de usuario/película, usamos el 
promedio general (por ejemplo).

Finalmente evaluamos

```{r}
# Error de predicción de calificaciones en validación con RECM
dat_valida %>% ungroup %>% summarise(error = recm(calif, pred))
```

**Observación**: ¿Qué tan bueno es este resultado? De 
[wikipedia](https://en.wikipedia.org/wiki/Netflix_Prize):

> Prizes were based on improvement over Netflix's own algorithm, called Cinematch, or the previous year's score if a team has made improvement beyond a certain threshold. A trivial algorithm that predicts for each movie in the quiz set its average grade from the training data produces an RMSE of $1.0540$. Cinematch uses "straightforward statistical linear models with a lot of data conditioning".
>
>Using only the training data, Cinematch scores an RMSE of $0.9514$ on the quiz data, roughly a 10% improvement over the trivial algorithm. Cinematch has a similar performance on the test set, $0.9525$. In order to win the grand prize of $1,000,000$, a participating team had to improve this by another $10%$, to achieve $0.8572$ on the test set. Such an improvement on the quiz set corresponds to an RMSE of $0.8563$.

Para este conjunto de datos, al menos tneemos mejor score que el algoritmo utilizado en su momento por netflix. Sin embargo, nótese que estrictamente hablando no podemos comparar nuestros resultados con estos números,
en los que se usa una muestra de prueba separada, de películas vistas despúes del periodo de entrenamiento.

### Ejercicio: regularización del modelo simple {-}

No hemos resulto el problema de películas o usarios con pocas evaluaciones. Como vimos arriba,
hay gran variablidad en los promedios de las películas con pocas evaluaciones, y esto produce
error adicional en nuestras predicciones.

```{r}
# Promedio de calificación por película 
medias_peliculas <- dat_netflix %>% group_by(peli_id) %>% summarise(media_peli = mean(calif), num_calif_peli = length(calif))

# Promedio general de calificaciones 
media_gral <- mean(dat_netflix$calif)

# Agrega la media de las peliculos a la base de datos de peliculas 
medias_p_2 <- left_join(medias_peliculas, pelis_nombres)

# Ordena por calificación promedio 
arrange(medias_p_2, desc(media_peli)) %>% head
```

Una opción es encoger calificaciones a la media dependiendo del tamaño de muestra. 
Por ejemplo:


$$
\hat{x_{ij}} = \hat{\mu} + \frac{n_i}{\lambda+n_i} \hat{c_i} + \frac{m_j}{\lambda+m_j}\hat{d_j} 
$$

Si hay muchas evaluaciones, esto va a hacer que el ponderador sea muy cercano a uno y tenemos la misma medida que antes. Si hay pocas evaluaciones, entonces el ponderador va a ser cercano a cero y le doy a la media general más peso porque no confío en lo que estoy observando. 


Entonces, la fórmula anterior equivale a encoger las predicciones hacia la media general cuando el número de evaluaciones es bajo. El grado de encogimiento depende de $\lambda$.

```{r, fig.width=5, fig.asp=0.7}
# Función para estimar calificaciones encogiendo por tamaño de muestra 
pred_encoger <- function(media, num_usuario, num_peli, media_usu, media_peli, calif, lambda){
        # coeficiente del usuario
        coef_usu <- num_usuario / (num_usuario + lambda) 
        
        # coeficiente de la película
        coef_peli <- num_peli / (num_peli + lambda) 
        
        # calcula la predicción de la calificación.
        pred <- media + coef_usu * (media_usu - media) + coef_peli * (media_peli - media)
        
        # en caso de que no haya califs de usuario o peli usa la media general. 
        pred <- ifelse(is.na(pred), media, pred) 
        
        # devuelve la predicción
        pred
    }

# Posibles lambdas
lambdas <- c(0.01, 0.1, 1, 5, 10, 20, 100)

# Calcula el error de validación para las diferentes lambdas 
error_valida <- map_dfr(lambdas, function(lambda){
  
    preds <- as.tibble(dat_valida) %>% # datos de validación
        mutate(pred_lambda = pred_encoger(media_total, num_calif_usu, num_calif_peli, 
                                     media_usu, media_peli, calif, lambda)) %>% # predicciones por tamaño de muestra 
        select(pred_lambda, calif) # selecciona variables 
    list(lambda = lambda, error = recm(preds$calif, preds$pred_lambda)) # devuelve lambda y su RECM
})

# Grafica el error de valdiación dependiendo del valor de lambda 
ggplot(error_valida, aes(x = lambda, y = error)) + geom_line() +
    scale_x_log10() + geom_point()
```


Fijándonos en la escala del eje "error", no logramos una mejora considerable. Veremos más adelante cómo lidiar con este problema de una mejor manera.



## Filtrado colaborativo: similitud

Además de usar promedios generales por película, podemos utilizar similitud de películas/personas
para ajustar predicciones según los gustos de artículos o películas similares. Este es el enfoque
más simple del filtrado colaborativo.


Comencemos entonces con la siguiente idea: Supongamos que queremos hacer una predicción
para el usuario $i$ en la película $j$, que no ha visto. Si tenemos una
medida de similitud entre películas, podríamos buscar películas *similares*
a $j$ que haya visto $i$, y ajustar la predicción según la calificación de estas películas similares.


Tomamos entonces nuestra predicción
base, que le llamamos $x_{ij}^0$ y hacemos una nueva predicción:

$$\hat{x}_{ij} = x_{ij}^0 + \frac{1}{k}\sum_{t \in N(i,j)} (x_{it} - x_{it}^0 )$$

donde $N(i,j)$ son películas similares a $j$ **que haya visto** $i$. Ajustamos $x_{ij}^0$ por el gusto promedio de películas similares a $j$, 
a partir de las predicciones base. Esto quiere decir
que si las películas similares a $j$ están evaluadas **por encima del esperado** para el usuario
$i$, entonces subimos la predicción, y bajamos la predicción cuando las películas similares
están evaluadas **por debajo de lo esperado**.

Nótese que estamos ajustando por los residuales del modelo base. Podemos también utilizar
un ponderado por gusto según similitud: si la similitud entre las películas $j$ y $t$ es $s_{jt}$,
entonces podemos usar

\begin{equation}
\hat{x}_{ij} = x_{ij}^0 + \frac{\sum_{t \in N(i,j)} s_{jt}(x_{it} - x_{it}^0 )}{\sum_{t \in N(i,j)} s_{jt}} 
(#eq:simprom)
\end{equation}

Cuando no tenemos películas similares que hayan sido calificadas por nuestro usuario,
**entonces usamos simplemente la predicción base**.


### Cálculo de similitud entre usuarios/películas {#simitems}

Proponemos utilizar la distancia coseno de las calificaciones centradas 
por usuario ya que esta distancia es un simil de la correlación (la diferencia es que aquí no centramos por columna sino por renglón). Como discutimos arriba, antes de calcular similitud conviene centrar las calificaciones por usuario
para eliminar parte de la heterogeneidad en el uso de la escala.


### Ejemplo {-}

```{r, echo = TRUE}
# Matriz de NA's para gustos de peliculas
mat.cons <- matrix(NA, 5, 6)

# LLena algunas entradas 
mat.cons[1,1] <- 5;mat.cons[1,2] <- 5;mat.cons[1,3] <- 5;mat.cons[1,4] <- 2
mat.cons[2,1] <- 3;mat.cons[2,3] <- 4;
mat.cons[3,4] <- 5; mat.cons[3,5] <- 4
mat.cons[4,1] <- 1;mat.cons[4,3] <- 2;mat.cons[4,5] <- 5;mat.cons[4,6] <- 4;
mat.cons[5,1] <- 4; mat.cons[5,2] <- 5; mat.cons[5,6] <- 2

# Filas-> usuarios, columnas-> peliculas
rownames(mat.cons) <- c('a','b','c','d','e')
colnames(mat.cons) <- c('SWars1','SWars4','SWars5','HPotter1','HPotter2','Twilight')

# Tabla
knitr::kable(mat.cons)
```

Calculamos medias por usuarios y centramos:

```{r}
# Calcula medias por usuario
medias_ej<-apply(mat.cons,1, mean, na.rm=TRUE)
medias_ej

#  Resta matriz de medias 
mat.c <- mat.cons - apply(mat.cons,1, mean, na.rm=TRUE)

# Tabla
knitr::kable(mat.c, digits = 2)
```

Y calculamos similitud coseno entre películas,  **suponiendo que las películas
no evaluadas tienen calificación $0$**:

```{r}
# Función de similitud coseno
sim_cos <- function(x,y){
  sum(x*y, na.rm = T)/(sqrt(sum(x^2, na.rm = T))*sqrt(sum(y^2, na.rm = T)))
}

# Películas 1 y 2
mat.c[,1]
mat.c[,2]

# Distancia coseno entre películas 1y 2.
sim_cos(mat.c[,1], mat.c[,2])

```

```{r}
# Distancia coseno entre peliculas 1 y 6
sim_cos(mat.c[,1], mat.c[,6])
```


**Observación**:
- Hacer este supuesto de valores $0$ cuando no tenemos evaluación no es lo mejor, pero 
como centramos por usuario tiene más sentido hacerlo. Si utilizaramos las calificaciones
no centradas, entonces estaríamos suponiendo que las no evaluadas están calificadas muy mal ($0$, por abajo de $1$,$2$,$3$,$4$,$5$).
- Si calculamos similitud entre *usuarios* de esta forma, las distancia coseno es simplemente el coeficiente de correlación. Nótese que estamos
calculando similitud entre *items*, centrando por usuario, y esto no
es lo mismo que correlación entre columnas.


### Ejemplo: ¿cómo se ven las calificaciones de películas similares/no similares? {-}

Centramos las calificaciones por usuario y seleccionamos tres películas que
pueden ser interesantes.

```{r}
# Centrar las calificaciones por media del usuario
dat_entrena_c <- dat_entrena %>% # datos de entrenamiento 
  group_by(usuario_id) %>% # agrupa por usuario
  mutate(calif_c = calif - mean(calif)) # centra la calificación

# calculamos un id secuencial.
dat_entrena_c$id_seq <- as.numeric(factor(dat_entrena_c$usuario_id))

# Busca la película "Gremlins" para extraer el id
filter(pelis_nombres, str_detect(nombre,'Gremlins'))

# Busca la película "When Harry Met Sally"" para extraer el id
filter(pelis_nombres, str_detect(nombre,'Harry Met'))

# Extre las calificaciones de cada una de las películas de interés 
dat_1 <- filter(dat_entrena_c, peli_id==6482) # "gremlins 1"
dat_2 <- filter(dat_entrena_c, peli_id==2897) # "gremlins 2"
dat_3 <- filter(dat_entrena_c, peli_id==2660) # "When Harry met Sally"
```

Juntamos usuarios que calificaron cada par:

```{r}
# Junta usuarios que calificaron Gremlins 1 y gremlins 2
comunes <- inner_join(dat_1[, c('usuario_id','calif_c')], dat_2[, c('usuario_id','calif_c')] %>% rename(calif_c_2=calif_c))

# Junta usuarios que calificaron Grlemins 1 y When harry met Sally
comunes_2 <- inner_join(dat_1[, c('usuario_id','calif_c')], dat_3[, c('usuario_id','calif_c')] %>% rename(calif_c_2=calif_c))
```

Y ahora graficamos. 

```{r, fig.width = 5, fig.asp = 0.7, message=FALSE, warning = FALSE}

# Grafica las calificaciones centradas de gremlins 1 y 2 
ggplot(comunes, aes(x=calif_c, y=calif_c_2)) + 
  geom_jitter(width = 0.2, height = 0.2, alpha = 0.5) + 
  geom_smooth() + xlab('Gremlins 1') + ylab('Gremlins 2')

# Grafica las calificaciones centradas de gremlins 1 y WHMS
ggplot(comunes_2, aes(x=calif_c, y=calif_c_2))  + 
  geom_jitter(width = 0.2, height = 0.2, alpha = 0.5) + 
  geom_smooth() + xlab('Gremlins 1') + ylab('When Harry met Sally')
```

Se puede ver que hay una asociación positiva entre Gremlins 1 y Gremlins 2 pero que no hay relación entre Gremlins 1 y When Harry Met Sally. 

**Pregunta**: ¿por qué los datos se ven en bandas? Las bandas aparecen porque son los rangoes con los que califican los usuarios. Por ejemplo, los que calificaron GGremlins con 4 y WHMS con 5 tienen puntos de la forma (4-b,5-b) con b la media del usuario, estos puntos s e ven como una línea ercta con pendiente positiva.


Y calculamos la similitud coseno:

```{r}
# Similitud coseno Gremlins 1 y Gremlins 2
sim_cos(comunes$calif_c, comunes$calif_c_2)

# Similitud coseno Gremlins 1 y WHSM
sim_cos(comunes_2$calif_c, comunes_2$calif_c_2)
```

Así que las dos Gremlins son algo similares, pero Gremlins $2$ y Harry Met Sally no son similares.

---


Podemos ahora seleccionar algunas películas y ver cuáles son películas similares que nos podrían ayudar a hacer recomendaciones:

```{r}
# Obtiene los datos de entrenamiento con calificaciones centradas
dat_entrena_2 <- dat_entrena_c %>% # datos entrenamiento agrupados
  ungroup() %>%  # desagrupa 
  select(peli_id, id_seq, calif_c) # selecciona variables 

# Funcíon para extaer ejemplos 
ejemplos <- function(pelicula){
  
  # Filtra por el id de la película. 
  mi_peli <- filter(dat_entrena_2, peli_id==pelicula) %>% # filtra calif. de la película 
             rename(peli_id_1 = peli_id, calif_c_1 = calif_c) # renombra columnas 
  
  # vamos a calcular todas las similitudes con mi_peli - esto no es buena
  # idea y discutiremos más adelante cómo evitarlo
  # pega las calif de la pelicula de interes con el resto. 
  datos_comp <- left_join(dat_entrena_2, mi_peli) 
  
  # calcular similitudes
  out_sum <- datos_comp %>% # datos completos 
      group_by(peli_id) %>% #agrupa por película 
      summarise(dist = sim_cos(calif_c, calif_c_1)) %>% #extrae similitud coseno
      left_join(medias_p_2) # agrega las medias ponderadas 
  
  # Ordena por distancia coseno y selecciona variables 
  out_sum %>% arrange(desc(dist))  %>% select(nombre, dist, num_calif_peli)
}

```

Nótese que las similitudes aparentan ser ruidosas si no filtramos por número de evaluaciones:

```{r}
# Película 8199 "The Purple Rose of Cairo"
ejemplos(8199) %>% head(20) %>% knitr::kable() # 20 pelis más parecidas
ejemplos(8199) %>% filter(num_calif_peli > 200) %>% head(20) %>% knitr::kable() # 20 pelis más parecidas filtrando por no de evaluaciones
```

```{r}
# Película 6807: "8 1/2"
ejemplos(6807) %>% head(20) %>% knitr::kable() # 20 pelis más parecidas
ejemplos(6807) %>% filter(num_calif_peli > 300) %>% head(20) %>% knitr::kable() # 20 pelis más parecidas filtrando por no. de evaluaciones
```

El problema otra vez es similitudes ruidosas que provienen de pocas evaluaciones en común. 

### Ejercicio {-}
Intenta con otras películas que te interesen (ver tarea 5 parte 1 para más ejemplos).

```{r}
# Friends: Season 1
ejemplos(11271) %>% filter(num_calif_peli>300) %>% head(20) 

# Anaconda
ejemplos(11929) %>% filter(num_calif_peli>300) %>% head(20)

# When Harry Met Sally
ejemplos(2660) %>% filter(num_calif_peli>300) %>% head(20)
```

### Implementación 

Si queremos implementar este tipo de filtrado colaborativo (por
similitud), el ejemplo de arriba no es práctico pues tenemos que
calcular todas las posibles similitudes. Sin embargo, como nos interesa
principalmente encontrar los pares de similitud alta, podemos usar LSH:

- Empezamos haciendo LSH de las películas usando el método de hiperplanos
aleatorios como función hash (pues este es el método que captura distancias coseno bajas). 
Nuestro resultado son todos los items
o películas agrupadas en cubetas. Podemos procesar las cubetas para
eliminar falsos positivos (o items con muy pocas evaluaciones).
- Ahora queremos estimar el rating del usuario $i$ de una película $j$
que no ha visto. Extraemos las cubetas donde cae la película $j$, y 
extraemos todos los items.
- Entre todos estos items, extraemos los que ha visto el usuario $i$,
y aplicamos el promedio \@ref(eq:simprom).

**Observaciones**

- En principio, este análisis podría hacerse usando similitud entre
usuarios en lugar de items. En la práctica (ver [@mmd]), el enfoque
de similitud entre items es superior, pues similitud es un concepto
que tiene más sentido en items que en usuarios (los usuarios pueden
tener varios intereses traslapados).
- Nótese que en ningún momento tuvimos que extraer variables de
películas, imágenes, libros, etc o lo que sea que estamos recomendando.
Esta es una fortaleza del filtrado colaborativo.
- Por otro lado, cuando tenemos pocas evaluaciones o calificaciones
este método no funciona bien (por ejemplo, no podemos calcular
las similitudes pues no hay traslape a lo largo de usuarios). En
este caso, este método puede combinarse con otros (por ejemplo, agregar
una parte basado en modelos de gusto por género, año, etc.)


## Dimensiones latentes para recomendación

En las similitudes que vimos arriba, es razonable pensar que hay ciertos "conceptos" 
que agrupan o separan películas, y así mismo, que los usuarios se distinguen por el gusto o no
que tienen por estos "conceptos".

En esta parte, consideramos la idea de utilizar reducción de dimensionalidad para
hacer recomendaciones. Esta idea propone que hay ciertos factores latentes (características no observadas)
que describen películas con "contenido implícito similar", y usuarios según su interés en esa dimensión.

Este método nos permitirá también controlar mejor los resultados ruidosos que
obtuvimos en los ejemplos anteriores (usando regularización y reducción
de dimensión).



### Ejemplo: una dimensión latente.{#ejemplo}
Por ejemplo: consideramos una dimensión de películas serias (valores positivos) contra películas divertidas (valores negativos).
3 películas (items) podrían describirse con

$$v=(-2,0,1)$$,

lo que interpretamos como la película 1 es divertida (negativa en seriedad-diversión), la película 2 está en promedio, y la película 3 es más seria que las dos anteriores.
 
Por otro lado, tenemos descriptores de 5 usuarios:

$$u=(2,3,-3,0,1)$$
que dice que a los primeros dos usuarios les gustan las películas serias, al tercero le gustan las divertidas, y los dos últimos no tienen preferencia clara a lo largo de esta dimensión.

Qusiéramos predecir el gusto usando estos dos vectores. Nuestras predicciones (considerando que u y v son matrices de una columna) serían simplemente

$$\tilde{X} = u v^t$$

Es decir, modelamos la calificación multiplicando el nivel de gusto por la seriedad del usuario y el nivel de seriedad de cada película. 

```{r}
# Define gusto de los usuarios por seria(+)-divertida(-)
u <- c(2,3,-3,0,1)
# Define las películas por seria(+)-divertida(-)
v <- c(-2,0,1)
```

En este caso, al usuario 3 le gustan las películas divertidas (-3) entonces , al multiplicar por el nivel de seriedad de la primer película (-2), dará un valor positivo y, por lo tanto, si le puede gustar la película uno. 


```{r}
# Estima las calificaciones
gustos <- u%*%t(v)

# Calificaciones estimadas
gustos
```

Esta matriz es la matriz de scores para cada persona sobre cada una de las películas en la lista. Recomendamos a cada usuario la película con mayor calificación. 
Así que al usuario 1 le recomendamos la película 3, pero al usuario 3 le recomendamos la película 1.

---

La idea es entonces encontrar pesos para películas $u$ y para usuarios $v$ de forma que
$X\approx \tilde{X} = uv^t$: podemos reproducir las calificaciones observadas a partir de nuestro modelo de factores latentes.

Nótese sin embargo que hay varias dimensiones que pueden describir a películas y usuarios:
por ejemplo, seria-divertida, artística-hollywood, ciencia ficción, con/sin violencia, etc. 
Podemos proponer más dimensiones latentes de la siguiente forma:


### Ejemplo: dos dimensiones latentes {#ejemplo}
Tenemos la dimensión anterior de seria-divertida
```{r}
# Define las películas por seria(+)/divertida(-)
v_1 <- c(-2,0,1)

# Define gusto de los usuarios por seria(+)/divertida(-)
u_1 <- c(2,3,-3,0,1)
```
En realidad, no puedo describir películas y gustos sólo con una dimensión. Entonces buscamos varias $u$'s y varias $v$'s de tal forma que las combinamos como una suma ponderada para obtener la predicción del score. 

Supongamos que tenemos otra dimensión con violencia - sin violencia
```{r}
# Define las películas por violencia(+)/sin violencia(-)
v_2 <- c(-3,2,2)

# Define gusto de los usuarios por violencia(+)/sin violencia(-)
u_2 <- c(-3,-3,0,-2,4)
```

Que quiere decir que las películas $2$ y $3$ tienen volencia, pero la película $1$ no. Por otra parte, a los usuarios 1,2 y 5 no les gustan las películas con violencia, mientras que al usuario 5 si les gustan.

La idea ahora es que el gusto de una persona por una película se escribe como combinación de las dos dimensiones. Por ejemplo, para la persona 1 tenemos, y la película 1, empezamos haciendo

```{r}
# Gusto del usuario uno por la película 1 bajo la dimensión 1
u_1[1]*v_1[1]

# Gusto del usuario uno por la película 1 bajo la dimensión 2
u_2[1]*v_2[1]
```

lo que quiere decir que el hecho de que la película 1 no sea seria le resta 4 en gusto (pues la película 1 está del lado "divertido"), pero le suma 9 en gusto, pues es una película sin violencia y esta persona está del lado "sin violencia".

Sumamos para encontrar el gusto total, es decir $x\sim u_1v_1'+u_2v_2'$. 

```{r}
# Gusto total del usuario uno por la pelicula uno.
u_1[1]*v_1[1] + u_2[1]*v_2[1]
```

Para calcular los gustos sobre todas las personas y películas, juntamos los vectores en matrices para tener los $k$ descriptores:

```{r}
# Gusto de los usuarios bajo todas las dimensiones
U <- cbind(u_1, u_2)

# Clasificación de las películas bajo todas las dimensiones. 
V <- cbind(v_1, v_2)

# Usuarios 
U

# Películas
V
```

- El renglón $j$ de $U$ son los valores en las dimensiones latentes para
la película $i$ (descriptores de usuarios).
- El renglón $j$ de $V$ son los valores en las dimensiones latentes para
el usuario $j$ (descriptores de películas)


Nota: las $u_i$'s y las $v_j$'s se llaman matrices de rango 1. 


De esta manera, se puede estimar la calificación de cada usuario para cada película realizando el producto
$$
\hat{X}=UV'
$$
es decir, en el ejemplo tenemos que
```{r}
# Estimación de las calificaciones de cada usuario para cada película. 
U %*% t(V)
```



```{block2, type ="resumen"}
Con $k$ dimensiones latentes, el modelo que proponemos es:

$$\tilde{X} = UV^t$$

donde $U$ es una matrix de $nxk$ (n= número de usuarios), y $V$ es una matriz
de $pxk$, donde $p$ es el número de películas.

Buscamos que, si $X$ son las verdaderas calificaciones, entonces
$$X\approx \tilde{X}.$$

y nótese que esta aproximación es en el sentido de las entradas de $X$ que **son observadas**. Sin embargo, $\tilde{X}$ nos da predicciones para **todos los pares usuario-película**.
```

Notar que $X$ es una matriz rala, pero $\tilde{X}$ es una matriz densa (siempre puedo tener una estimación de la calificación de cada usuario para cada película). 


Si quisieramos tener una suma ponderada, entonces estimaríamos las calificaciones como $\tilde{X}=U\LambdaV'$ con $\Lambda$ matriz diagonal de pesos. 


Bajo este modelo, la predicción para el usuario $i$ y la película $j$
es la siguiente suma sobre las dimensiones latentes:

$$\tilde{x}_{ij} =\sum_k u_{ik} v_{jk}$$

que expresa el hecho de que el gusto de $i$ por $j$ depende de una combinación (suma)
de factores latentes de películas ponderados por gusto por esos factores del usuario.


El número de factores latentes $k$ debe ser seleccionado por ejemplo, según el error de validación. Dado $k$, para encontrar $U$ y $V$ (un total de $k(n+p)$ parámetros) buscamos
minimizar 

$$\sum_{(i,j)\, obs} (x_{ij}-\tilde{x}_{ij})^2,$$


que también podemos escribir este problema (recuérdese que $u_i$ y
$v_j$ aquí son vectores renglón) como

$$\min_{U,V}\sum_{(i,j)\, obs} (x_{ij}-u_iv_j^t)^2$$
donde $u_i$ es el renglón $i$-esimo de $U$ (gustos latentes del usuario $i$ en cada dimensión), y $v_j$ es el renglón $j$-ésimo de la matriz $V$ (calificación latente de la película en cada dimensión)


```{block2, type='resumen'}
**¿Por qué funciona la idea de factores latentes?**

- El método de factorización de matrices de grado bajo ($k$)
funciona compartiendo información a lo largo de películas y usuarios. Como tenemos
que ajustar los datos observados, y solo tenemos a nuestra disposición $k$
  descriptores para cada película y usuario, una minimización exitosa
captura regularidades en los datos.

- Es importante que la representación sea de grado relativamente bajo,
pues esta "compresión" es la que permite que las dimensiones 
latentes capturen regularidades que están en los datos observados (que
esperamos encontrar en el proceso de ajuste). 
```


Por ejemplo, supongamos que el gusto por las películas sólo depende de
una dimensión seria - divertida. Si ajustamos un modelo de un solo
factor latente, un **mínimo** se alcanzaría separando con la dimensión latente
las películas serias de las divertidas, y los usuarios que prefieren películas
serias o divertidas. Esta sería una buena explicación de los datos observados,
y las predicciones para películas no vistas sería buena usando simplemente
el valor en seriedad de la película (extraída de otras personas con gustos
divertido o serio) y el gusto por seriedad de esa persona (extraida de la 
observación de que le gustan otras películas serias u otras divertidas).

### Combinación con modelo base

Podemos usar también ideas de nuestro modelo base y modelar desviaciones en lugar de calificaciones directamente:

Si $X^0$ son las predicciones del modelo de referencia, y
$$R = X-X^0$$
son los residuales del modelo base, buscamos mejor
$$R\approx \tilde{X} = UV^t$$
de manera que las predicciones finales son
$$X^0 + \tilde{X}$$

Veremos también más adelante cómo regularizar estos sesgos como
parte de la construcción del modelo.

## Factorización de matrices.

Como vimos arriba, reexpresamos nuestro problema como un problema
de factorización de matrices  (encontrar $U$ y $V$). Hay varias alternativas populares para atacarlo:

- Descomposición en valores singulares (SVD).
- Mínimos cuadrados alternados.
- Descenso en gradiente estocástico.

Para entender más del primer enfoque, puedes consultar por ejemplo
las notas del curso de aprendizaje de máquina <https://felipegonzalez.github.io/aprendizaje-maquina-2017/reduccion-de-dimensionalidad.html>. No vamos a ver más de este enfoque, pues no
es del todo apropiado: nuestras matrices tienen muchos datos faltantes, y SVD naturalmente no está diseñado para lidiar con este problema. Se pueden hacer ciertas imputaciones (por ejemplo, insertar 0's una vez que centramos por usuario), pero los siguientes dos métodos están mejor adaptados para
nuestro problema.

## Mínimos cuadrados alternados.

Supongamos entonces que queremos encontrar matrices $U$ y $V$, donde $U$ es una matrix de $nxk$ (n= número de usuarios), y $V$ es una matriz
de $pxk$, donde $p$ es el número de películas que nos de una
aproximación de la matrix $X$ de calificaciones
$$
X \approx UV^t
$$
Ahora supongamos que conocemos $V_1$. Si este es el caso, entonces queremos
resolver para $U_1$:
$$ \min_{U_1}|| X - U_1V_1^t||_{obs}^2$$
Como $V_1^t$ están fijas, este es un problema de mínimos cuadrados usual, y puede resolverse analíticamente (o usar descenso en gradiente, que
es simple de calcular de forma analítica) para encontrar $U_1$. Una vez que encontramos $U_1$, la fijamos, e intentamos ahora resolver para $V$:

$$ \min_{V_2}|| X - U_1V_2^t||_{obs}^2$$
Y una vez que encontramos $V_2$ resolvemos

$$ \min_{U_2}|| X - U_2V_2^t||_{obs}^2$$

Continuamos este proceso hasta encontrar un mínimo local o hasta cierto número de iteraciones. Notar que cada paso es un paso de MCO y pueden exisitir varios mínimos locales; de hecho, todas las permutaciones de $U$ y $V$ son una solución de mínimos cuadrados para el problema. Para inicializar $V_1$, en [@alsreg] se recomienda tomar como primer
renglón el promedio de las calificaciones de las películas, y el resto 
números aleatorios chicos (por ejemplo $U(0,1)$). También pueden inicializarse con números
aleatorios chicos las dos matrices.

### Mínimos cuadrados alternados con regularización

Si hay pocas calificaciones para una películas o personas con pocas evaluaciones, esto puede llevar a tener estimadores muy ruidosos por falta de observaciones. La solución propuesta es utilizar regularización. La idea es que la regugalización va a encoger a cero los coeficientes de la matriz rala que correspondan a pocas observaciones. 


Para agregar regularización y lidiar con los datos ralos, podemos
incluir un coeficiente adicional. Minimizamos entonces (como en
 [@alsreg]):

$$\min_{U,V}\sum_{(i,j)\, obs} (x_{ij}-u_i^tv_j)^2 + 
\lambda \left ( \sum_i n_{i}||u_i||^2 + \sum_j m_{j} ||v_j||^2 \right)$$

y modificamos de manera correspondiente cada paso de mínimos cuadrados
mostrado arriba. $n_{i}$ es el número de evaluaciones del usuario $i$, y
$m_j$ es el número de evaluaciones de la película $j$.

**Observaciones**:

- Nótese que penalizamos el tamaños de los vectores $u_i$ y $v_j$ para evitar sobreajuste (como en regresión ridge).
- Nótese también que los pesos $n_i$ y $m_j$ en esta regularización hace comparables el término que aparece en la suma de los residuales al cuadrado
(la primera suma),
y el término de regularización: por ejemplo, si el usuario $i$ hizo
$n_i$ evaluaciones, entonces habrá $n_i$ términos en la suma de la izquierda. Lo mismo podemos decir acerca de las películas.
- Este no es el único término de regularización posible. Por ejemplo, podríamos *no* usar los pesos $n_i$ y $m_j$, y obtendríamos
un esquema razonable también, donde hay más regularización relativa
para usuarios/películas que tengan pocas evaluaciones.

Este método está implementado en [spark](https://spark.apache.org/docs/2.1.0/mllib-collaborative-filtering.html). La implementación está basada parcialmente en [@alsreg]. La inicialización
es diferente en spark, ver [el código](https://github.com/apache/spark/blob/v2.2.0/mllib/src/main/scala/org/apache/spark/ml/recommendation/ALS.scala), donde cada renglón se inicializa con
un vector de $N(0,1)$ normalizado.

En este caso, copiamos nuestra tabla a spark (nota: esto es algo que normalmente no haríamos, los datos habrían sido cargados en el cluster
de spark de otra forma):

```{r,  message=FALSE, warning=FALSE}
# Elimina algunas variables que ya no necesitamos 
rm(list = c('dat_netflix', 'dat_entrena_2','dat_entrena_c'))

# Carga la librería para conectarse a spark
library(sparklyr)

# configuración para spark
config <- spark_config()

# Amplía la memoria. 
config$`sparklyr.shell.driver-memory` <- "4G"
```

```{r}
# conectar con "cluster" local
sc <- spark_connect(master = "local", config = config)

# Hace un plan de cómo va a ejecutar las taras que se le piden. 
spark_set_checkpoint_dir(sc, './checkpoint')
```

Y copiamos la tabla a Spark:

```{r leertabla}
# Carga la tabla a spark desde R. 
# NOTA: esto normalmente no lo hacemos en R
dat_tbl <- spark_read_csv(sc, name="netflix", "../datos/netflix/dat_muestra_nflix.csv") 

# Elimina la fecha 
dat_tbl <- dat_tbl %>% select(-fecha)

# Copia las tablas de validación y entrenamiento a spark desde R. 
# Notar que estos no tienen tanto problema porque son más chiquitos.  
valida_tbl <- copy_to(sc, dat_valida %>% select(-fecha))

# Nota: este anti-join corre en spark y no en la memoria de R. 
entrena_tbl <- dat_tbl %>% anti_join(valida_tbl) 
```

Vamos a hacer primero una descomposición en 15 factores,
con regularización relativamente alta:

```{r als-spark}
# Corre el modelo de factores latentes 
# rating_col es la col con las calificaciones
# user_col es la col con los usuarios
# item_col es la columna con los items (peliculas)
# Rank es el no. de factores
# reg_param es el parámetro de regularización
# El check point evita que la gráfica de cálculo sea demasiado grande. 
# Cada 5 iteraciones hace una nueva gráfica con los resultados de la última iteración. 
modelo <- ml_als(entrena_tbl, 
              rating_col = 'calif',
              user_col = 'usuario_id',
              item_col = 'peli_id', 
              rank = 15, reg_param = 0.05,
              checkpoint_interval = 5,
              max_iter = 50)
# Nota: para ver los trabajos de spark entrar en http://localhost:8787/p/4040/jobs.
# Es necesario haber levantado un segundo puerto en el docker. 
```

```{r}
# Resúmen del modelo. 
modelo
```

Hacemos predicciones para el conjunto de validación:

```{r, warning = FALSE, message = FALSE, fig.width=5, fig.asp=0.7}

# Obtenemos las predicciones. 
# Hace las predicciones en spark y lo traemos a R con collect
preds <- sdf_predict(valida_tbl, modelo) %>% collect() 

# Tabla de frecuencias de las predicciones faltantes
table(is.nan(preds$prediction))

# Histograma de las calificaciones. 
ggplot(preds, aes(x = prediction)) + geom_histogram()
```

Y ahora calculamos el error de validación, sustituyendo 
los usuarios o películas que no fueron vistas en entrenamiento
por la media general (podríamos usar la predicción del modelo base).

```{r}
# Sustituye los usuarios/películas que no fueron vistas en el entrenamiento por la media general. 
# 
preds$prediction[is.nan(preds$prediction)] <- 3.6

# Calcula la raíz del ECM de las predicciones 
preds %>% ungroup %>% summarise(error = recm(calif, prediction))
```

Y ahora sí redujimos considerablemente el error respecto al modelo base (se redujo a 0.84). Examinamos 
ahora las dimensiones asociadas con películas (V's):


```{r}
# Extaemos de spark a R la matriz de factores asociados a las películas. 
V_df <- collect(modelo$item_factors)

# Dimensiones 
dim(V_df)
```

```{r}
# Vistazo de V
V_df
```

Nota: La columna *features* contiene la misma información de *feature_1,feature_2,...*, pero en forma de lista.

Examinemos la interpretación de los factores latentes de las
películas. 

```{r}
# Agrega id de pelicula, la media y los nombres. 
latentes_pelis <- V_df %>% 
  left_join(pelis_nombres %>% left_join(medias_peliculas) %>% rename(id = peli_id))

# Divide las v'j en 10 cubetas 
latentes_pelis <- latentes_pelis %>% 
    mutate(num_grupo = ntile(num_calif_peli, 10))
```

Para la primera dimensión latente:


```{r}
# Primer factor 
feature <- quo(features_1)


arrange(latentes_pelis, !!feature) %>% # ordena por factores
  select(nombre, !!feature, media_peli, num_calif_peli) %>%  # selecciona variables 
  filter(num_calif_peli > 2000) %>%  # filtra películas con más de 2mil calificaciones
  head(100) # primeras 100 
```

Todas estas películas tienene el feature\_1 negativo y parecen ser "películas de niñas" es decir, novelas románticas, comedias románticas, etc. 

```{r}
arrange(latentes_pelis, !!feature) %>% # ordena por factores
  select(nombre, !!feature, media_peli, num_calif_peli) %>% # selecciona variables 
  filter(num_calif_peli > 2000) %>% # filtra películas con más de 2mil calificaciones
  tail(100) # Últimas 100 películas 
```

Todas estas películas son "películas de niño" es decir, mayormente de acción y violencia. Además todos los valores son positivos, por lo que la primer componente sí parece estar capturando una diferencia en las películas. 


La segunda dimensión latente:

```{r}
# Segundo factor 
feature <- quo(features_2)


arrange(latentes_pelis, !!feature) %>% # ordena por factores
  select(nombre, !!feature, media_peli, num_calif_peli) %>%  # selecciona variables 
  filter(num_calif_peli > 2000) %>%  # filtra películas con más de 2mil calificaciones
  head(100) # primeras 100 
```

Pareciera que esta dimensión está tratando de capturar el gusto por la serie de Friends. Todos los valores son negativos. Veamos las últimas observaciones.  

```{r}
arrange(latentes_pelis, !!feature) %>% # ordena por factores
  select(nombre, !!feature, media_peli, num_calif_peli) %>% # selecciona variables 
  filter(num_calif_peli > 2000) %>% # filtra películas con más de 2mil calificaciones
  tail(100) # Últimas 100 películas 
```

Parecen ser títulos más viejos que no son series de televisión.Estos valores son positivos. 

La tercera dimensión latente:

```{r}
# Tercer factor 
feature <- quo(features_3)


arrange(latentes_pelis, !!feature) %>% # ordena por factores
  select(nombre, !!feature, media_peli, num_calif_peli) %>%  # selecciona variables 
  filter(num_calif_peli > 2000) %>%  # filtra películas con más de 2mil calificaciones
  head(100) # primeras 100 
```

Pareciera que esta dimensión está tratando de separar las películas de ficción/acción. 

```{r}
arrange(latentes_pelis, !!feature) %>% # ordena por factores
  select(nombre, !!feature, media_peli, num_calif_peli) %>% # selecciona variables 
  filter(num_calif_peli > 2000) %>% # filtra películas con más de 2mil calificaciones
  tail(100) # Últimas 100 películas 
```
Aqui tanto los primeros como los últimos son negativos, pero cambian bastante en magnitud. 

```{r}
# Se desconecta de spark
sparklyr::spark_disconnect_all()
```

### Ejercicio {-}
Examina otras dimensiones latentes, ¿qué puedes interpretar?


## Descenso en gradiente estocástico

En esta parte veremos otra manera de construir factorización de matrices
para filtrado colaborativo, usando descenso en gradiente estocástico. Este método es similar a mínimos cuadrados alternados (ALS).

Para un recordatorio de descenso en gradiente, y la versión
estocástica, puedes ver por ejemplo, el artículo de
[wikipedia - Stochastic Gradient Descent](https://en.wikipedia.org/wiki/Stochastic_gradient_descent) 
o las [notas de aprendizaje 
de máquina](https://felipegonzalez.github.io/aprendizaje-maquina-2017/redes-neuronales-parte-2.html#descenso-estocastico).


Consideremos el problema de factorización que queremos resolver.
Si $X$ ($n\times p$) es la matriz de calificaciones, quisieramos encontrar matrices $U$ y $V$ (de tamaños $n\times k$ y $p\times k$) tales que
$$X\approx UV^t,$$
donde los reglones de $U$ son los descriptores de los usuarios
y los renglones de $V$ son los descriptores de las películas (ver sección anterior). Más expecíficamente, buscamos minimizar

\begin{equation}
\min_{U,V} \sum_{(i,j) obs} (x_{ij} - u_iv_j^t)^2
\end{equation}
donde $u_i$ es el renglón $i-ésimo$ de $U$ y $v_j$ es el renglón
$j$-ésimo de $V$. En términos de sus componentes, queremos minimizar

\begin{equation}
L =  \sum_{(i,j) obs} (x_{ij} - \sum_{l=1}^k u_{i,l}v_{j,l})^2
\end{equation}

Escribimos $$ L_{i,j} = e_{i,j}^2 =  (x_{ij} - \sum_{l=1}^k u_{i,l}v_{j,l})^2$$.

Para encontrar el gradiente, derivamos con respecto a cada parámetro
($u_{i,l}$ y $v_{j,l}$). Empezamos con cada término $L_{i,j}$:

$$\frac{\partial L_{i,j}}{\partial u_{i,s}} = -2e_{i,j} v_{j,s}
$$

y
$$\frac{\partial L_{i,j}}{\partial v_{j,t}} = -2e_{i,j} u_{i,t}
$$

El resto de las derivadas son iguales a 0 $\left(\text{para otros} u_a^{(m)}, v_b^{(m)}\right)$. Esto nos da la dirección del gradiente en cada paso del descenso estocástico. 

```{block2, type = 'comentario'}
Sea $\gamma >0$ el tamaño de paso (tasa de aprendizaje) de descenso estocástico.
Para cada evaluación $x_{i,j}$, la actualización de descenso está dada por,
en forma vectorial:
                                                                            
$$
u_i^{(n+1)} = u_i^{(n)} +\gamma e_{i,j} v_j^{(n)}
$$
y
$$
v_j^{(n+1)} = v_j^{(n)} +\gamma e_{i,j} u_j^{(n)}
$$
  
Inicializamos las matrices $U$ y $V$ con valores aleatorios chicos.
```
  
### Agregando el modelo base (sesgos)

Podemos también agregar el modelo base (que a veces es llamado modelo
con *sesgos*):

\begin{equation}
L =  \sum_{(i,j) obs} (x_{ij} - a_i - b_j - \sum_{l=1}^k u_{i}^{(l)}v_{j}^{(l)})^2
\end{equation}

Y las derivadas adicionales están dadas por

$$\frac{\partial L_{i,j}}{\partial a_i} = -2e_{i,j} 
$$

$$\frac{\partial L_{i,j}}{\partial b_j} = -2e_{i,j} 
$$

y el resto de las derivadas (para otras $a_s$ y $b_t$) son iguales a 0.


```{block2, type='resumen'}
- Nótese que en cada paso de descenso estocástico, las actualizaciones
sólo involucran los parámetros asociados con el usuario/película 
que estamos evaluando, y el cálculo es simple.
- No necesitamos tener en memoria todos los datos, podemos leerlos
en lotes y procesar cada lote sucesivemante.
```

### Regularización

Finalmente, podemos agregar regularización para controlar el sobreajuste
(por ejemplo, usuarios con pocas evaluaciones, o películas con
pocas evaluaciones). 

La función a minimizar es ahora

\begin{equation}
L =  \sum_{(i,j) obs} (x_{ij} - \mu - a_i - b_j - \sum_{l=1}^k u_{i,l}v_{j,l})^2 +
\lambda \left (  \sum_i ||u_i||^2 +  \sum_j ||v_j||^2 +  \sum_i a_i^2 + \sum_j b_j^2 \right )
(\#eq:regdescenso)
\end{equation}

donde también es posible usar parámetros de regularización distintos ($\lambda$) para
los vectores y los sesgos.

```{block2, type = 'resumen'}
Sea $\gamma >0$ el tamaño de paso (tasa de aprendizaje) de descenso estocástico,
y $\lambda \geq 0$ una constante de regularización. Sea $n_i$ el número
de evaluaciones del usuario $i$ y $m_j$ el número de evaluaciones para
la película $j$.
Para cada evaluación $x_{i,j}$, la actualización de descenso está dada,
en forma vectorial, por:
                                                                            
$$
u_i^{(n+1)} = u_i^{(n)} + \gamma \left ( e_{i,j} v_j^{(n)} - \frac{\lambda}{n_i} u_i^{(n)} \right )
$$
  
y

$$
v_j^{(n+1)} = v_j^{(n)} + \gamma \left ( e_{i,j} u_j^{(n)} -  \frac{\lambda}{m_j} v_j^{(n)} \right )
$$


Para los sesgos, las actualizaciones son (no regularizamos la media global):

$$\mu^{(n+1)} = \mu^{(n)} + \gamma e_{i,j}$$
  
$$a_i^{(n+1)} = a_i^{(n)} + \gamma \left ( e_{i,j} - \frac{\lambda}{n_i} a_i^{(n)} \right )$$
  
$$b_j^{(n+1)} = b_i^{(n+1)} + \gamma \left ( e_{i,j} - \frac{\lambda}{m_j} b_j^{(n)} \right )$$
  
Inicializamos las matrices $U$ y $V$ con valores aleatorios chicos.
```

- Puedes ver [este video](https://www.youtube.com/watch?v=GGWBMg0i9d4&index=56&list=PLLssT5z_DsK9JDLcT8T62VtzwyW9LNepV), de los autores de nuestro libro de texto

- Nótese que dividimos entre el número de evaluaciones de usuarios y películas a la
constante de regularización. Esto se puede entender observando que el término
de regularización en \@ref(eq:regdescenso) se puede poner bajo la suma
dividiendo por estos factores. También se puede observar que el valor esperado
del gradiente calculado de esta manera es \@ref(eq:regdescenso) (excepto por
un factor constante).

- Este es un tipo de regularización distinto al que usamos en el ejemplo
de mínimos cuadrados alternados.

### Ejemplo (netflix)
Usaremos una  implementación en C++ para tener mejor desempeño 
(una introducción a extensiones de C++ para R está en 
[@advanced-r]).


```{r}
# Carga librería
library(Rcpp)
# Carga archivos .cpp
Rcpp::sourceCpp('../src/factorizacion_mat/descenso_estocastico.cpp')
Rcpp::sourceCpp('../src/factorizacion_mat/calc_error_bias.cpp')
```

```{r, comment=""}
# Nota: esto es eficiente en el uso de memoria y no está haciendo 
# copias de tablas y/u objetos como R. 
cat(readLines('../src/factorizacion_mat/descenso_estocastico.cpp'), sep = "\n")
```


Por ejemplo:

```{r}
# Carga librería 
library(Matrix)

# --- entrenamiento---
set.seed(1182)

#permutamos para las rondas de descenso estocástico
permutacion <- sample(1:length(dat_entrena$usuario_id), 
                      length(dat_entrena$usuario_id))

# Índice de usuario
i <- dat_entrena$usuario_id[permutacion]

# Índice de película 
j <- dat_entrena$peli_id[permutacion]

# Calif del usuario i para la pelicula j
y <- dat_entrena$calif[permutacion]


# --- validación ---
# Índice de Usuario 
i_val <- dat_valida$usuario_id

# Índice de Película 
j_val <- dat_valida$peli_id

# Calificación usuario i película j en validación 
y_val <- dat_valida$calif
```

Podemos agregar también dos usuarios nuevos con evaluaciones
opuestas (puedes llenar con tus preferencias)
```{r}
# Id de usuario nvo 1
i_usuario_1 <- rep(100001, 12)

# Id de usurio nvo 2
i_usuario_2 <- rep(100002, 12)

# Películas a evaluar para estos usuarios
nombres_evaluar <- data_frame(nombre = 
                    c('Ghost', 'Pretty Woman', 'Driving Miss Daisy',
                      'The Fast and the Furious', 'Meet the Fockers',
                     'Independence Day', 'Top Gun',
                     'Being John Malkovich', 'A Clockwork Orange', 
                     'Fight Club', 'Pulp Fiction',
                     'The Terminator'))

# Evaluaciones del usuario nvo 1
evals_1 <- c(1, 2, 2, 4, 3, 4, 4, 2, 4, 5, 5, 5)

# Evaluaciones del usuario nvo 2 (opuestas)
evals_2 <- 6 - evals_1

# Asigna evaluación del usuario nvo 1 a las películas
nombres_evaluar$evals <- evals_1

# Vemos los datos. 
nombres_evaluar

# Extrae el id de las películas a evaluar  
j_evaluar <- medias_pelis %>% semi_join(nombres_evaluar) %>% pull(peli_id)

```



```{r descenso}
# Algoritmo de descenso estocástico

# usuarios
i <- c(i, i_usuario_1, i_usuario_2)

# películas
j <- c(j, j_evaluar, j_evaluar)

# calificaciones 
y <- c(y, evals_1, evals_2)

# Crea la matriz de datos (tiene muchos missings, i.e. es una matriz rala)
X <- sparseMatrix(i, j, x = y, dims=c(max(i), 17770))
dim(X)
```

```{r}
#otra manera de inicializar es con resultados de SVD
#library(irlba)
#test <- irlba(X, nv = 4, nu = 4)
#U_0 <- test$u%*%sqrt(diag(test$d))
#V_0 <- test$v%*%sqrt(diag(test$d))

#inicialización para 4 factores 
set.seed(2805)

# Matrices iniciales aleatorias con 4 factores.
U_0 <- matrix(rnorm(4 * max(i), 0, 0.01), ncol = 4)
V_0 <- matrix(rnorm(4 * 17770, 0, 0.01), ncol = 4)

# Fija los parametros iniciales 
U <- U_0
V <- V_0

# Extrae número calificaciones por usuarios y por películas 
num_usu <- rowSums(X>0) + 1
num_peli <- colSums(X>0) + 1

# Calcula la calificación promedio
mu <- mean(y)

# Media por usuario
a <- rowSums(X)/rowSums(X>0) - mean(y)
a[is.nan(a)] <- 0

# Media por película 
b <- colSums(X)/colSums(X>0) -  mean(y)
print(sqrt(calc_error(i, j, y, U, V, mu, a, b)))

# Corre 10 iteraciones del algoritmo 
for(iter in 1:10){
  
  # nota: la función descenso_gradiente (C++) no hace copias de U,V,a,b
  # cambia in-place estos parámetros
  # tasa de aprendizaje =0.005, param regularización=10 (ambos)
  salida <- descenso_estocastico(i, j, y, U, V, mu, a, b, 
              gamma = 0.005, lambda_mat = 10, lambda_sesgos = 10,
              n_iter = 1, num_peli, num_usu)
  
  # Calcula la raíz del error de entrenamiento 
  error_entrena <- sqrt(calc_error(i, j, y, U, V, mu, a, b))
  
  # Calcula la raiz del error de validación 
  error_valida <- sqrt(calc_error(i_val, j_val, y_val, U, V, mu, a, b))
  
  # Imprime resultados
  sprintf("Iteración: %i, Error entrena: %.4f, Error valida: %.4f", 
                        iter,
                        error_entrena, error_valida) %>% print

}
```

Notar que el error de entrenamiento y de validación son muy cercanos. Cuando hay una divergencia muy grande estos (entrenamiento muy chico y validación muy grande) se tiene un indicador de sobre ajuste del modelo. Para controlar esto, tenemos las u's, v's y $\lambda$. Lo primero que podemos hacer es regularizar más o tomar menos factores. 


Notar también que aumentar el número de factores siempre hará que disminuya el error de entrenamiento pero tienes más riesgo de sobreajustar el modelo. 


Veamos las preferencias para el primer usuario.

```{r}

# Extraemos el usuario nuevo 1. 
usuario_1_u <- U[100001, ]

# Obtenemos las preferencias por cada película disponible 
prefs_1 <- mu + a[100001] + b + V %*% usuario_1_u %>% as.numeric

# Extraemos las películas mejor evaluadas 
prefs <- data_frame(prefs = prefs_1, peli_id = 1:17770) %>%  # crea data frame 
  left_join(medias_pelis, by = 'peli_id') %>% # agerga la media de las películas 
  arrange(desc(prefs)) %>% # ordena por preferencia 
  filter(num_calif_peli > 500) %>% # filtra por mas de 500 evaluaciones
  select(peli_id, nombre, prefs) %>% # selecciona variables 
  top_n(100, prefs) # primeras 100 mejor evaluadas

# Imprime la tabla 
 DT::datatable(prefs)
```

Por lo tanto, lo que le recomendaríamos al primer usuario, sería el Señor de los anillos, lost, starwars, etc... 

Veamos el segundo usuario.

```{r}
# Extrae al usuario nuevo 2
usuario_2_u <- U[100002, ]

# Calcula preferencias 
prefs_2 <- mu + a[100002] + b + V %*% usuario_2_u %>% as.numeric

# Extrae preferencias 
prefs <- data_frame(prefs = prefs_2, peli_id = 1:17770) %>% # crea data frame 
  left_join(medias_pelis) %>% # agrega media de peliculas
  arrange(desc(prefs)) %>% # ordena por preferencias
  filter(num_calif_peli > 500) %>% # filtra por numero de calificaciones 
  select(nombre, prefs) %>% top_n(100, prefs) # primeras 100 mejor evaluadas

# Tabla 
DT::datatable(prefs)
```

Vemos que, como intencionalmente lo diseñamos, al usuario 2 se le harían recomendaciones totalmente opuestas a las del usuario uno (salvo por lost): Sex and the city, the west wing, gilmore girls, etc. 

Filtramos para ver películas bien conocidas, y muestreamos para
empezar a entender el significado de las dimensiones:

```{r, fig.width = 10, fig.asp = 0.7}
# Carga librería
library(ggrepel)

# Extrae las características para las películas  y agrega nombre y media 
V_df <- as_data_frame(V) %>% mutate(peli_id=1:nrow(V)) %>%
  left_join(medias_pelis) 

# Fija la semilla 
set.seed(12211)

# Toma una muestra de 100 películas con más de 10mil calificaciones 
muestra_graf <- V_df %>%
  filter(num_calif_peli > 10000) %>%
  sample_n(100)

# Grafica las películas, el color representa la media
ggplot(muestra_graf,
       aes(x = V1, y= V2, label=nombre, colour=media_peli))+
  geom_point() +
  geom_text_repel(size=3.5, segment.alpha = 0.3, direction = 'y')+
  ggtitle('Dimensiones 1 y 2')+
  theme(plot.title = element_text(hjust=0.5))
```

Podemos percibir algunas agrupaciones por $V1$ y $V2$ aunque no es trivial identificar de qué componente se trata. 

```{r, fig.width = 10, fig.asp = 0.7}
ggplot(muestra_graf,
       aes(x = V3, y= V4, label=nombre, colour=media_peli))+
  geom_point() + 
  geom_text_repel(size=3.5, segment.alpha = 0.3, direction='y')+
  ggtitle('Dimensiones 3 y 4')+
  theme(plot.title = element_text(hjust=0.5))
```
Pareciera que en al parte superior derecha tenemos novelas y comedias románticas, mientras que en la parte inferior izquierda tenemos películas de ciencia ficción y acción, en la parte inferior izauierda películas "tontas". 


En la distribución de las películas en el espacio de dimensiones podemos
apreciar el efecto del encogimiento (distribución del no. de evaluaciones) :

```{r}
# Cuantiles para le número de calificaciones 
quantile(V_df$num_calif_peli, probs = seq(0, 1, 0.1))

# Grafica de dimensiones por cuantiles. 
ggplot(V_df, aes(x = V1, y= V2, label=nombre)) +
  geom_point(alpha=0.5, size=0.5) + 
  facet_wrap(~ntile(num_calif_peli, 10)) 
```

Las calificaciones para las películas con menor numero de calificaciones están concentradas cerca del cero y las otras están más expandidas. 


## Más acerca del concurso de Netflix


Para tener desempeño equivalente los ganadores del concurso de Netflix
([@Bellkor]),
todavía faltan algunos elementos:

- A partir de 2004, hubo mejoras a la interfaz de Netflix. Esto provocó
un incremento general en las calificaciones. Este es un factor (el tiempo),
que es necesario incluir en el modelo como término adicional (si la calificación
es antes o después del cambio).

En esta gráfica vemos el promedio local de las calificaciones conforme
transcurre el tiempo:

```{r, fig.width = 6, fig.asp=0.7}
# Carga librería
library(lubridate)

# Grafica las calificaciones a lo largo del tiempo para una muestra de los datos de entrenamiento.
ggplot(sample_n(dat_entrena, 5000), aes(x= ymd(fecha), y = calif)) + 
  geom_smooth(method = 'loess', span=0.3)+
  xlab('Fecha')+
  ylab('Calificaciones')

```


- Otro efecto, por ejemplo, es que películas más antiguas tienen
calificaciones más altas (esto puede ser porque son las "sobreviven" en
los catálogos).

```{r, fig.width = 6, fig.asp=0.7}
# Gráfica de calificaciones promedio para películas con más de 1000 eval
ggplot(filter(medias_pelis, num_calif_peli > 1000), 
       aes(x = año, y = media_peli)) + 
  geom_point(alpha=0.4) + geom_smooth(method = 'loess',  span=0.4)+
  xlab('Año')+
  ylab('Calificación Promedio por Película')

```

- Finalmente, el equipo ganador combinó varios métodos para mejorar la 
predicción (factores latentes, filtrado colaborativo, en varias versiones,
y otros (ver por ejemplo [este artículo](https://amba-bigdata.wikispaces.com/file/view/Netflix_general.pdf)).


## Retroalimentación implícita

Esta sección está basada en [@recomendacion-implicita].

En el ejemplo que vimos arriba, la retroalimentación es expícita en el 
sentido de que los usuarios califican los artículos (1- no me gustó nada,
hasta 5- me gustó mucho). Sin embargo, es común encontrar casos
donde no existe esta retroalimentación explícita, y solo tenemos medidas
del gusto implícito, por ejemplo:

- Cuántas veces un usuario ha pedido un cierto artículo.
- Qué porcentaje del programa fue visto.
- Cuánto tiempo pasó en la página web.
- Cuántas veces oyó una canción.

Estos datos tienen la ventaja de que describen acciones del usuario,
en lugar de un rating que puede estar influido por sesgos de imagen
o de la calificación que "debería" tener un artículo además 
de la preferencia: quizá
disfruto muchísimo *Buffy the Vampire Slayer*, pero lo califico con un 3,
aunque un documental de ballenas que simplemente me gustó le pongo un 5.
En los datos implícitos se vería de todas formas mi consumo frecuente
de *Buffy the Vampire Slayer*, y quizá unos cuantos de documentales 
famosos.


Cada vez es más raro poner calificaciones explícitas porque necesitar hacer que el usuario asigne una calificación y no se tiene un uso homogéneo de la escala. Es más conveniente utilizar datos implícitos en la actividad del usuario. 


Sea $r_{ij}$ una medida implícita como las mencionadas arriba, para el usuario
$i$ y el artículo $j$. Ponemos $r_{i,j}=0$ cuando no se ha observado interacción
entre este usuario y el artículo. 


Una diferencia importante con los ratings explícitos es que los datos
implícitos son en un sentido menos informativos que los explícitos:

- Puede ser que el valor de $r_{ij}$ sea relativamente bajo (pocas interacciones), pero de todas formas se trate de un artículo que es muy preferido (por ejemplo, solo vi Star Wars I una vez, pero me gusta mucho). Esto no pasa con los ratings, pues ratings bajos indican baja preferencia.

- Sin embargo, estamos seguros de que niveles altos de interacción (oyó muchas veces una canción, etc.), es indicación de preferencia alta.

- Así que en nuestro modelo no necesariamente queremos predecir directamente la variable $r_{ij}$: puede haber artículos con predicción baja de $r_{ij}$ que
descubramos de todas formas van a ser altamente preferidos.


Una solución propuesta en [@recomendacion-implicita] (e implementada en 
spark) es darle menos importancia al valor $r_{ij}$ en la construcción
de los factores latentes. Para hacer esto, primero definimos
la variable de preferencia

$$p_{ij} = 
\begin{cases}
1 &\mbox{si } r_{ij}>0\\ 
0 &\mbox{si } r_{ij}=0\\
\end{cases}$$

Esta variable $p_{ij}$, cuando vale uno, indica algún nivel de preferencia.
¿Pero qué tanto valor debemos darle a esta preferencia? Definimos la confianza
como
$$c_{ij} = 1+ \alpha r_{ui},$$
donde $\alpha$ es un parámetro que hay que afinar (por ejemplo $\alpha$ entre 1 y 50). Para predicciones de vistas de TV, en [@recomendacion-implicita] utilizan
$\alpha = 40$, donde $r_{ij}$ es el número de veces que el usuario ha visto
un programa (contando vistas parciales, así que es un número real).

La función objetivo (sin regularización) se define como

\begin{equation}
L =  \sum_{(i,j)} c_{ij}(p_{ij}  - \sum_{l=1}^k u_{i,l}v_{j,l})^2
(#eq:implicita)
\end{equation}

Nótese la diferencia con el caso explícito. En este caso, los valores
de $c_{ij}$ (confianza) actúan como un pesos en el ajuste de
los factores, indicando que valores altos de $r_{ij}$ son más informativos y
deben contribuir más en el ajuste, sin descalificar que un
artìculo con $r_{ij}$ bajo puede ser preferido. Adicionalmente, los valores
para los cuales $p_{ij}=0$ son los que reciben el peso mínimo ($c_{ij}=1$).

Igual que en los ejemplos anteriores, usualmente se agregan términos
de regularización para los vectores renglón $u_i$ y $v_j$. Como en
el paper original, este problema se puede resolver usando mínimos cuadrados
alternados.

### Evaluación para modelos implícitos

La evaluación para modelos implícitos no es tan simple como
en el caso explícito, pues no estamos modelando
directamente los valores observados $r_{ij}$.  Medidas
como RECM o MAD que usamos en el caso explícito
no son tan apropiadas para este problema. 

Una alternativa es, para cada usuario $i$, ordenar los artículos de 
mayor a menor valor de $\hat{p}_{ij} = u_iv_j^t$ (canciones, pellículas), y calcular

$$
rank = \frac{\sum_{j} p_{ij}rank_{i,j}}{\sum_j p_{ij}}
$$

donde $rank_{ij}$ es el percentil del artículo $j$ en la lista ordenada
de artículos. $rank_{ij}=0$ para el mejor artículo, y $rank_{ij}=1$ para el peor.

Esta suma es un promedio sobre los rankings del usuario con $p_{ij}=1$, 
y **menores valores son mejores** (quiere decir que hubo alguna preferencia
por los items con $rank_{ij}$ bajo, es decir, los mejores de nuestra lista predicha. Es posible también hacer un promedio ponderado
por $r_{ij}$:
$$
rank = \frac{\sum_{j} r_{ij}rank_{i,j}}{\sum_j r_{ij}}
$$
que es lo mismo que la ecuación anterior pero ponderando por el interés mostrado
en cada artículo con $p_{ij}=1$.

- Menores valores de $rank$ son mejores.
- Si escogemos al azar el ordenamiento de los artículos, el valor esperado de $rank_{ij}$ es 0.5 (en medio de la lista), lo que implica que el valor esperado
de $rank$ es 0.50. Cualquier modelo con $rank\geq 0.5$ es peor que dar recomendaciones al azar.

Esta cantidad la podemos evaluar en entrenamiento y en validación. Para construir
el conjunto de validación podemos hacer:

- Escogemos un número de usuarios para validación (por ejemplo 20\%)
- Ponemos 50\% de los artículos evaluados por estas personas en validación, por ejemplo.

Estas cantidades dependen de cuántos datos tengamos, como siempre, para tener
un tamaño razonable de datos de validación.


